{
    "training_class": "DPO",
    "training_args": {
        "model_id": "Qwen/Qwen2.5-32B-Instruct",
        "lora": "SeppeV/SFT_joketailor_qwen32B",
        "dataset_id": "SeppeV/dpo_ds_test",
        "percentage_data": 100,
        "trainer_config": {
            "hub_model_id": "dpo_qwen32B",
            "output_dir": "/scratch/leuven/368/vsc36814/dpo_qwen32B",
            "report_to": "wandb",
            "run_name": "dpo_qwen32B",
            "per_device_train_batch_size": 2,
            "per_device_eval_batch_size": 2,
            "save_total_limit": 2,
            "eval_strategy": "epoch",
            "push_to_hub": true
        },
        "lora_config": {
            "lora_alpha": 16,
            "lora_dropout": 0.1,
            "r": 64,
            "bias": "none",
            "task_type": "CAUSAL_LM"
        },
        "bnb_config": {
            "load_in_4bit": true,
            "bnb_4bit_quant_type": "nf4",
            "bnb_4bit_use_double_quant": false
        },
        "prompt": "Generate a joke for user {userId}"
    }
}